{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miladbahrami-fs/Independent_Causal_Mechanisms/blob/main/LICM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_1MVp5RbwcT",
        "outputId": "b506cd34-100f-47e9-cd69-639e70647910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n",
            "Collecting protobuf>=4.22.3 (from tensorboardX)\n",
            "  Downloading protobuf-4.23.3-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, tensorboardX\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "Successfully installed protobuf-4.23.3 tensorboardX-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import time\n",
        "import os\n",
        "from tensorboardX import SummaryWriter\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NwwFiDVYtiol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "# dataset = getattr(datasets, 'MNIST')\n",
        "# train_transform = transforms.Compose([transforms.ToTensor()])\n",
        "# kwargs_train = {'download': True, 'transform': train_transform}\n",
        "# dataset_train = dataset(root='./data', train=True, **kwargs_train)\n",
        "dataset_train = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "dataset_test = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "4_xktOtGtCja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Sample Data\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(dataset_train), size=(1,)).item()\n",
        "    img, label = dataset_train[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "9Ynu63nJdkGu",
        "outputId": "0db63f69-a7e5-402b-c8d4-9709e2c8a9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Test Dataset Size\n",
        "print('Train Size: {}, Test Size: {}'.format(len(dataset_train),len(dataset_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02hY005teIax",
        "outputId": "48299d22-720f-4380-9e95-c0babe684eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Size: 60000, Test Size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "outdir = '.' #path to the output directory\n",
        "optimizer_experts = 'adam' # optimization algorithm (options: sgd | adam)\n",
        "optimizer_discriminator ='adam' # optimization algorithm (options: sgd | adam)\n",
        "optimizer_initialize ='adam' # optimization algorithm (options: sgd | adam)\n",
        "batch_size = 128 # input batch size for training\n",
        "input_size = 784 # input size of data\n",
        "epochs = 100 # number of epochs to train\n",
        "epochs_init = 100 # number of epochs to initially train experts\n",
        "no_cuda = False # enables CUDA training\n",
        "seed = 11 # random seed\n",
        "log_interval = 10 # how many batches to wait before logging training status\n",
        "learning_rate_initialize = 1e-1 # size of expert learning rate\n",
        "learning_rate_expert = 1e-3 #size of expert learning rate\n",
        "learning_rate_discriminator =1e-3 # size of discriminator learning rate\n",
        "name = '' #name of experiment\n",
        "weight_decay = 0 # weight decay for optimizer\n",
        "num_experts = 5 # number of experts\n",
        "load_initialized_experts = False # whether to load already pre-trained experts\n",
        "model_for_initialized_experts ='' # path to pre-trained experts\n",
        "cuda = not no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "_e5I8bmNfMcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataloader from dataset\n",
        "data_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=int(cuda), pin_memory=cuda)"
      ],
      "metadata": {
        "id": "gvBwnc3MwjvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "A-i5D6oFmp75"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk9oaoUcc9SR"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random seed\n",
        "torch.manual_seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Name of The Experiment\n",
        "timestamp = str(int(time.time()))\n",
        "if name == '':\n",
        "    name = 'n_exp_{}_bs_{}_lri_{}_lre_{}_lrd_{}_ei_{}_e_{}_oi_{}_oe_{}_oe_{}_{}'.format(\n",
        "        num_experts, batch_size, learning_rate_initialize,\n",
        "        learning_rate_expert, learning_rate_discriminator, epochs_init,\n",
        "        epochs, optimizer_initialize, optimizer_experts, optimizer_discriminator,\n",
        "        timestamp)\n",
        "else:\n",
        "    name = '{}_{}'.format(name, timestamp)\n",
        "\n",
        "print('\\nExperiment: {}\\n'.format(name))\n",
        "\n",
        "# Logging. To run: tensorboard --logdir <args.outdir>/logs\n",
        "log_dir = os.path.join(outdir, 'logs')\n",
        "if not os.path.exists(log_dir):\n",
        "    os.mkdir(log_dir)\n",
        "log_dir_exp = os.path.join(log_dir, name)\n",
        "os.mkdir(log_dir_exp)\n",
        "writer = SummaryWriter(log_dir=log_dir_exp)\n",
        "\n",
        "# Directory for checkpoints\n",
        "checkpt_dir = os.path.join(outdir, 'checkpoints')\n",
        "if not os.path.exists(checkpt_dir):\n",
        "    os.mkdir(checkpt_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUGYJ5jXgk-8",
        "outputId": "2b093909-883a-40e9-ddd5-de453d420ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Experiment: n_exp_5_bs_128_lri_0.1_lre_0.001_lrd_0.001_ei_100_e_100_oi_adam_oe_adam_oe_adam_1687976292\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Expert(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Expert, self).__init__()\n",
        "\n",
        "        # Architecture\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Linear(in_feat, out_feat)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(input_size, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, input_size),\n",
        "            nn.Tanh()\n",
        "            )\n",
        "\n",
        "    def forward(self, input):\n",
        "        breakpoint()\n",
        "        print(input.shape)\n",
        "        print(input.dtype)\n",
        "        output = self.model(input)\n",
        "        return output"
      ],
      "metadata": {
        "id": "eZZNGeR6eJPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Architecture\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        validity = self.model(input)\n",
        "        return validity"
      ],
      "metadata": {
        "id": "gSjMcQ4cmVn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_expert(epochs, expert, i, optimizer, loss, data_train, writer):\n",
        "    print(\"Initializing expert [{}] as identity on preturbed data\".format(i+1))\n",
        "    expert.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        n_samples = 0\n",
        "        # breakpoint()\n",
        "        for batch in data_train:\n",
        "            x_canonical, x_transf = batch\n",
        "            batch_size = x_canonical.size(0)\n",
        "            n_samples += batch_size\n",
        "            x_transf = x_transf.view(x_transf.size(0), -1).to(device)\n",
        "            x_transf = x_transf.to(torch.float32)\n",
        "            x_hat = expert(x_transf)\n",
        "            loss_rec = loss(x_hat, x_transf)\n",
        "            total_loss += loss_rec.item()*batch_size\n",
        "            optimizer.zero_grad()\n",
        "            loss_rec.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Loss\n",
        "        mean_loss = total_loss/n_samples\n",
        "        print(\"initialization epoch [{}] expert [{}] loss {:.4f}\".format(epoch+1, i+1, mean_loss))\n",
        "        writer.add_scalar('expert_{}_initialization_loss'.format(i+1), mean_loss, epoch+1)\n",
        "        if mean_loss < 0.002:\n",
        "            break\n",
        "\n",
        "    torch.save(expert.state_dict(), checkpt_dir + '/{}_E_{}_init.pth'.format(name, i + 1))"
      ],
      "metadata": {
        "id": "gda4ox0iAd_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_system(epoch, experts, discriminator, optimizers_E, optimizer_D, criterion, data_train, writer):\n",
        "    discriminator.train()\n",
        "    for i, expert in enumerate(experts):\n",
        "        expert.train()\n",
        "\n",
        "    # Labels for canonical vs transformed samples\n",
        "    canonical_label = 1\n",
        "    transformed_label = 0\n",
        "\n",
        "    # Keep track of losses\n",
        "    total_loss_D_canon = 0\n",
        "    total_loss_D_transformed = 0\n",
        "    n_samples = 0\n",
        "    total_loss_expert = [0 for i in range(len(experts))]\n",
        "    total_samples_expert = [0 for i in range(len(experts))]\n",
        "    expert_scores_D = [0 for i in range(len(experts))]\n",
        "    expert_winning_samples_idx = [[] for i in range(len(experts))]\n",
        "\n",
        "    # Iterate through data\n",
        "    for idx, batch in enumerate(data_train):\n",
        "        x_canon, x_transf = batch\n",
        "        # x_transf = torch.randn(x_canon.size()) # TODO temporary since do not have the preturbed data yet\n",
        "        batch_size = x_canon.size(0)\n",
        "        n_samples += batch_size\n",
        "        x_canon = x_canon.view(batch_size, -1).to(device)\n",
        "        x_transf = x_transf.view(batch_size, -1).to(device)\n",
        "\n",
        "        # Train Discriminator on canonical distribution\n",
        "        scores_canon = discriminator(x_canon)\n",
        "        labels = torch.full((batch_size,), canonical_label, device=device).unsqueeze(dim=1)\n",
        "        loss_D_canon = criterion(scores_canon, labels)\n",
        "        total_loss_D_canon += loss_D_canon.item() * batch_size\n",
        "        optimizer_D.zero_grad()\n",
        "        loss_D_canon.backward()\n",
        "\n",
        "        # Train Discriminator on experts output\n",
        "        labels.fill_(transformed_label)\n",
        "        loss_D_transformed = 0\n",
        "        exp_outputs = []\n",
        "        expert_scores = []\n",
        "        for i, expert in enumerate(experts):\n",
        "            exp_output = expert(x_transf)\n",
        "            exp_outputs.append(exp_output.view(batch_size, 1, input_size))\n",
        "            exp_scores = discriminator(exp_output.detach())\n",
        "            expert_scores.append(exp_scores)\n",
        "            loss_D_transformed += criterion(exp_scores, labels)\n",
        "        loss_D_transformed = loss_D_transformed / num_experts\n",
        "        total_loss_D_transformed += loss_D_transformed.item() * batch_size\n",
        "        loss_D_transformed.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train experts\n",
        "        exp_outputs = torch.cat(exp_outputs, dim=1)\n",
        "        expert_scores = torch.cat(expert_scores, dim=1)\n",
        "        mask_winners = expert_scores.argmax(dim=1)\n",
        "\n",
        "        # Update each expert on samples it won\n",
        "        for i, expert in enumerate(experts):\n",
        "            winning_indexes = mask_winners.eq(i).nonzero().squeeze(dim=-1)\n",
        "            accrue = 0 if idx == 0 else 1\n",
        "            expert_winning_samples_idx[i] += (winning_indexes+accrue*n_samples).tolist()\n",
        "            n_expert_samples = winning_indexes.size(0)\n",
        "            if n_expert_samples > 0:\n",
        "                total_samples_expert[i] += n_expert_samples\n",
        "                exp_samples = exp_outputs[winning_indexes, i]\n",
        "                D_E_x_transf = discriminator(exp_samples)\n",
        "                labels = torch.full((n_expert_samples,), canonical_label,\n",
        "                                    device=device).unsqueeze(dim=1)\n",
        "                loss_E = criterion(D_E_x_transf, labels)\n",
        "                total_loss_expert[i] += loss_E.item() * n_expert_samples\n",
        "                optimizers_E[i].zero_grad()\n",
        "                loss_E.backward(retain_graph=True) # TODO figure out why retain graph is necessary\n",
        "                optimizers_E[i].step()\n",
        "                expert_scores_D[i] += D_E_x_transf.squeeze().sum().item()\n",
        "\n",
        "    # Logging\n",
        "    mean_loss_D_generated = total_loss_D_transformed / n_samples\n",
        "    mean_loss_D_canon = total_loss_D_canon / n_samples\n",
        "    print(\"epoch [{}] loss_D_transformed {:.4f}\".format(epoch + 1, mean_loss_D_generated))\n",
        "    print(\"epoch [{}] loss_D_canon {:.4f}\".format(epoch + 1, mean_loss_D_canon))\n",
        "    writer.add_scalar('loss_D_canonical', mean_loss_D_canon, epoch + 1)\n",
        "    writer.add_scalar('loss_D_transformed', mean_loss_D_generated, epoch + 1)\n",
        "    for i in range(len(experts)):\n",
        "        print(\"epoch [{}] expert [{}] n_samples {}\".format(epoch + 1, i + 1, total_samples_expert[i]))\n",
        "        writer.add_scalar('expert_{}_n_samples'.format(i + 1), total_samples_expert[i], epoch + 1)\n",
        "        writer.add_text('expert_{}_winning_samples'.format(i + 1),\n",
        "                           \":\".join([str(j) for j in expert_winning_samples_idx[i]]), epoch + 1)\n",
        "        if total_samples_expert[i]> 0:\n",
        "            mean_loss_expert = total_loss_expert[i] / total_samples_expert[i]\n",
        "            mean_expert_scores = expert_scores_D[i] / total_samples_expert[i]\n",
        "            print(\"epoch [{}] expert [{}] loss {:.4f}\".format(epoch + 1, i + 1, mean_loss_expert))\n",
        "            print(\"epoch [{}] expert [{}] scores {:.4f}\".format(epoch + 1, i + 1, mean_expert_scores))\n",
        "            writer.add_scalar('expert_{}_loss'.format(i + 1), mean_loss_expert, epoch + 1)\n",
        "            writer.add_scalar('expert_{}_scores'.format(i + 1), mean_expert_scores, epoch + 1)"
      ],
      "metadata": {
        "id": "W90mRU5nk4X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(model, path):\n",
        "    pre_trained_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
        "    for layer in pre_trained_dict.keys():\n",
        "        model.state_dict()[layer].copy_(pre_trained_dict[layer])\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True"
      ],
      "metadata": {
        "id": "4jyCt9R_hnlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "experts = [Expert().to(device) for i in range(num_experts)]\n",
        "discriminator = Discriminator().to(device)"
      ],
      "metadata": {
        "id": "Z2r3Zgel5g0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Losses\n",
        "loss_initial = torch.nn.MSELoss(reduction='mean')\n",
        "criterion = torch.nn.BCELoss(reduction='mean')"
      ],
      "metadata": {
        "id": "xqGpDxko7qRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Experts as approximately Identity on Transformed Data\n",
        "for i, expert in enumerate(experts):\n",
        "    if load_initialized_experts:\n",
        "        path = os.path.join(checkpt_dir,\n",
        "                            model_for_initialized_experts + '_E_{}_init.pth'.format(i+1))\n",
        "        init_weights(expert, path)\n",
        "    else:\n",
        "        if optimizer_initialize == 'adam':\n",
        "            optimizer_E = torch.optim.Adam(expert.parameters(), lr=learning_rate_initialize,\n",
        "                                                weight_decay=weight_decay)\n",
        "        elif optimizer_initialize == 'sgd':\n",
        "            optimizer_E = torch.optim.SGD(expert.parameters(), lr=learning_rate_initialize,\n",
        "                                              weight_decay=weight_decay)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        initialize_expert(epochs_init, expert, i, optimizer_E, loss_initial, data_train, writer)\n"
      ],
      "metadata": {
        "id": "3h1C9aIW9_-v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "5072e3b0-4ae9-435d-8829-b1c0674bc585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing expert [1] as identity on preturbed data\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-b7e7701bcba8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0minitialize_expert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_E\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-10bd3e3dca53>\u001b[0m in \u001b[0;36minitialize_expert\u001b[0;34m(epochs, expert, i, optimizer, loss, data_train, writer)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mx_transf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_transf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_transf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mx_transf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_transf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_transf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mloss_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_transf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-2a7a856a6804>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x1 and 784x128)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next(iter(data_train))[0].dtype\n",
        "for i, expert in enumerate(experts):\n",
        "  print(expert.parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfDr9CS_Yg7m",
        "outputId": "36ce08f5-83c0-4f60-92a5-08c413e3dfdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.parameters of Expert(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (3): BatchNorm1d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (6): BatchNorm1d(512, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Linear(in_features=512, out_features=1024, bias=True)\n",
            "    (9): BatchNorm1d(1024, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Linear(in_features=1024, out_features=784, bias=True)\n",
            "    (12): Tanh()\n",
            "  )\n",
            ")>\n",
            "<bound method Module.parameters of Expert(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (3): BatchNorm1d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (6): BatchNorm1d(512, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Linear(in_features=512, out_features=1024, bias=True)\n",
            "    (9): BatchNorm1d(1024, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Linear(in_features=1024, out_features=784, bias=True)\n",
            "    (12): Tanh()\n",
            "  )\n",
            ")>\n",
            "<bound method Module.parameters of Expert(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (3): BatchNorm1d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (6): BatchNorm1d(512, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Linear(in_features=512, out_features=1024, bias=True)\n",
            "    (9): BatchNorm1d(1024, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Linear(in_features=1024, out_features=784, bias=True)\n",
            "    (12): Tanh()\n",
            "  )\n",
            ")>\n",
            "<bound method Module.parameters of Expert(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (3): BatchNorm1d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (6): BatchNorm1d(512, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Linear(in_features=512, out_features=1024, bias=True)\n",
            "    (9): BatchNorm1d(1024, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Linear(in_features=1024, out_features=784, bias=True)\n",
            "    (12): Tanh()\n",
            "  )\n",
            ")>\n",
            "<bound method Module.parameters of Expert(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (3): BatchNorm1d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (6): BatchNorm1d(512, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Linear(in_features=512, out_features=1024, bias=True)\n",
            "    (9): BatchNorm1d(1024, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Linear(in_features=1024, out_features=784, bias=True)\n",
            "    (12): Tanh()\n",
            "  )\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in data_train:\n",
        "    x_canonical, x_transf = batch\n",
        "    print(x_canonical.size(0))\n",
        "    print(x_transf.shape)\n",
        "    print(x_transf.view(x_transf.size(0), -1).shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxib8FzIpku0",
        "outputId": "2994b001-04bb-4743-bfe7-c98f4585f21b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n",
            "torch.Size([128])\n",
            "torch.Size([128, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizers\n",
        "optimizers_E = []\n",
        "for i in range(num_experts):\n",
        "    if optimizer_experts == 'adam':\n",
        "        optimizer_E = torch.optim.Adam(experts[i].parameters(), lr=learning_rate_expert,\n",
        "                                        weight_decay=weight_decay)\n",
        "    elif optimizer_experts == 'sgd':\n",
        "        optimizer_E = torch.optim.SGD(experts[i].parameters(), lr=learning_rate_expert,\n",
        "                                      weight_decay=weight_decay)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    optimizers_E.append(optimizer_E)\n",
        "\n",
        "if optimizer_discriminator == 'adam':\n",
        "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=learning_rate_discriminator,\n",
        "                                    weight_decay=weight_decay)\n",
        "elif optimizer_discriminator == 'sgd':\n",
        "    optimizer_D = torch.optim.SGD(discriminator.parameters(), lr=learning_rate_discriminator,\n",
        "                                    weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "ui8oNaL5kNKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "for epoch in range(epochs):\n",
        "    train_system(epoch, experts, discriminator, optimizers_E, optimizer_D, criterion, data_train, writer)\n",
        "\n",
        "    if epoch % log_interval == 0 or epoch == epochs-1:\n",
        "        torch.save(discriminator.state_dict(), checkpt_dir + '/{}_D.pth'.format(name))\n",
        "        for i in range(num_experts):\n",
        "            torch.save(experts[i].state_dict(), checkpt_dir + '/{}_E_{}.pth'.format(name, i+1))"
      ],
      "metadata": {
        "id": "72r4wwfXkiAE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgfaICUcTwH19p7rclfnyu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}